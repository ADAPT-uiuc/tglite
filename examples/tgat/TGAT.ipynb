{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F4O-2MjGfOMr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import tglite as tg\n",
        "\n",
        "from tgat import TGAT\n",
        "import support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tH_6K5u3iQhy"
      },
      "outputs": [],
      "source": [
        "DATA: str = 'wiki'  # 'wiki', 'reddit', 'mooc', 'mag', 'lastfm', 'gdelt', 'wiki-talk'\n",
        "DATA_PATH: str = '/shared'\n",
        "EPOCHS: int = 10\n",
        "BATCH_SIZE: int = 200\n",
        "LEARN_RATE: float = 0.0001\n",
        "DROPOUT: float = 0.1\n",
        "N_LAYERS: int = 2\n",
        "N_HEADS: int = 2\n",
        "N_NBRS: int = 20\n",
        "DIM_TIME: int = 100\n",
        "DIM_EMBED: int = 100\n",
        "N_THREADS: int = 32\n",
        "SAMPLING: str = 'recent'  # 'recent'or 'uniform'\n",
        "OPT_DEDUP = True\n",
        "OPT_CACHE = True\n",
        "OPT_TIME = True\n",
        "OPT_ALL = True\n",
        "OPT_DEDUP: bool = OPT_DEDUP or OPT_ALL\n",
        "OPT_CACHE: bool = OPT_CACHE or OPT_ALL\n",
        "OPT_TIME: bool = OPT_TIME or OPT_ALL\n",
        "CACHE_LIMIT: int = int(2e6)\n",
        "TIME_WINDOW: int = int(1e4)\n",
        "\n",
        "MOVE = True\n",
        "GPU = 0\n",
        "SEED = 1\n",
        "PREFIX = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = support.make_device(GPU)\n",
        "model_path = support.make_model_path('tgat', PREFIX, DATA)\n",
        "if SEED >= 0:\n",
        "    support.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "COgTQXmcgCEr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num edges: 157474\n",
            "num nodes: 9228\n",
            "edge feat: torch.Size([157474, 172])\n",
            "node feat: torch.Size([9228, 172])\n"
          ]
        }
      ],
      "source": [
        "### load data\n",
        "\n",
        "g = support.load_graph(os.path.join(DATA_PATH, f'data/{DATA}/edges.csv'))\n",
        "support.load_feats(g, DATA, DATA_PATH)\n",
        "dim_efeat = 0 if g.efeat is None else g.efeat.shape[1]\n",
        "dim_nfeat = g.nfeat.shape[1]\n",
        "\n",
        "g.set_compute(device)\n",
        "if MOVE:\n",
        "    g.move_data(device)\n",
        "\n",
        "ctx = tg.TContext(g)\n",
        "ctx.need_sampling(True)\n",
        "ctx.enable_embed_caching(OPT_CACHE, DIM_EMBED)\n",
        "ctx.enable_time_precompute(OPT_TIME)\n",
        "ctx.set_cache_limit(CACHE_LIMIT)\n",
        "ctx.set_time_window(TIME_WINDOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5-YKifBwLuMS"
      },
      "outputs": [],
      "source": [
        "### model\n",
        "\n",
        "sampler = tg.TSampler(N_NBRS, strategy=SAMPLING, num_threads=N_THREADS)\n",
        "model = TGAT(ctx,\n",
        "    dim_node=dim_nfeat,\n",
        "    dim_edge=dim_efeat,\n",
        "    dim_time=DIM_TIME,\n",
        "    dim_embed=DIM_EMBED,\n",
        "    sampler=sampler,\n",
        "    num_layers=N_LAYERS,\n",
        "    num_heads=N_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    dedup=OPT_DEDUP,)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DLZ8cipJLx-u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0:\n",
            "  loss:295.7572 val ap:0.9739 val auc:0.9782\n",
            "  epoch | total:14.08s loop:12.34s eval:1.74s\n",
            "   loop | forward:7.82s backward:4.46s sample:0.49s prep_batch:0.05s prep_input:1.03s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:1.15s time_nbrs:0.93s self_attn:3.64s\n",
            "epoch 1:\n",
            "  loss:170.5700 val ap:0.9828 val auc:0.9853\n",
            "  epoch | total:13.69s loop:11.75s eval:1.94s\n",
            "   loop | forward:6.86s backward:4.83s sample:0.50s prep_batch:0.05s prep_input:0.93s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.21s time_nbrs:1.18s self_attn:3.71s\n",
            "epoch 2:\n",
            "  loss:142.4620 val ap:0.9828 val auc:0.9855\n",
            "  epoch | total:14.43s loop:12.56s eval:1.86s\n",
            "   loop | forward:7.24s backward:5.26s sample:0.48s prep_batch:0.05s prep_input:0.82s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.25s time_nbrs:1.30s self_attn:3.99s\n",
            "epoch 3:\n",
            "  loss:128.9173 val ap:0.9850 val auc:0.9872\n",
            "  epoch | total:13.71s loop:12.58s eval:1.12s\n",
            "   loop | forward:6.61s backward:5.91s sample:0.52s prep_batch:0.06s prep_input:0.55s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.27s time_nbrs:0.96s self_attn:3.47s\n",
            "epoch 4:\n",
            "  loss:123.7265 val ap:0.9852 val auc:0.9874\n",
            "  epoch | total:16.85s loop:15.26s eval:1.58s\n",
            "   loop | forward:7.32s backward:7.84s sample:0.82s prep_batch:0.09s prep_input:0.52s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.41s time_nbrs:1.28s self_attn:3.50s\n",
            "epoch 5:\n",
            "  loss:116.0836 val ap:0.9843 val auc:0.9871\n",
            "  epoch | total:16.34s loop:14.75s eval:1.58s\n",
            "   loop | forward:7.10s backward:7.56s sample:0.79s prep_batch:0.08s prep_input:0.51s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.40s time_nbrs:1.27s self_attn:3.39s\n",
            "epoch 6:\n",
            "  loss:113.4501 val ap:0.9877 val auc:0.9894\n",
            "  epoch | total:18.37s loop:17.14s eval:1.21s\n",
            "   loop | forward:7.92s backward:9.13s sample:0.81s prep_batch:0.08s prep_input:0.51s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.41s time_nbrs:1.21s self_attn:3.82s\n",
            "epoch 7:\n",
            "  loss:108.1715 val ap:0.9869 val auc:0.9889\n",
            "  epoch | total:18.27s loop:17.03s eval:1.23s\n",
            "   loop | forward:7.81s backward:9.12s sample:0.65s prep_batch:0.09s prep_input:0.52s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.41s time_nbrs:1.20s self_attn:3.81s\n",
            "epoch 8:\n",
            "  loss:103.1291 val ap:0.9882 val auc:0.9897\n",
            "  epoch | total:17.87s loop:16.68s eval:1.18s\n",
            "   loop | forward:7.59s backward:8.99s sample:0.64s prep_batch:0.09s prep_input:0.50s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.39s time_nbrs:1.17s self_attn:3.71s\n",
            "epoch 9:\n",
            "  loss:101.0907 val ap:0.9899 val auc:0.9912\n",
            "  epoch | total:18.85s loop:17.23s eval:1.61s\n",
            "   loop | forward:7.75s backward:9.36s sample:0.85s prep_batch:0.11s prep_input:0.56s post_update:0.00s\n",
            "   comp | mem_update:0.00s time_zero:0.43s time_nbrs:1.32s self_attn:3.64s\n",
            "best model at epoch 9\n",
            "loading saved checkpoint and testing model...\n",
            "  test time:1.54s AP:0.9854 AUC:0.9876\n"
          ]
        }
      ],
      "source": [
        "### training\n",
        "\n",
        "train_end, val_end = support.data_split(g.num_edges(), 0.7, 0.15)\n",
        "neg_sampler = lambda size: np.random.randint(0, g.num_nodes(), size)\n",
        "\n",
        "trainer = support.LinkPredTrainer(\n",
        "    ctx, model, criterion, optimizer, neg_sampler,\n",
        "    EPOCHS, BATCH_SIZE, train_end, val_end,\n",
        "    model_path, None)\n",
        "\n",
        "trainer.train()\n",
        "trainer.test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
