{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "<img src=\"../img/colab.svg\" alt=\"Colab icon\" width=\"30\">  <span> &thinsp;</span> [Run in Google Colab](https://colab.research.google.com/drive/1wo4iZVCchqMDqUqpYK3ogtzb-ebMAS7g)\n",
    "<span> &emsp;</span>\n",
    "<img src=\"../img/github.svg\" alt=\"Colab icon\" width=\"30\">  <span> &thinsp;</span> [View on GitHub](https://github.com/ADAPT-uiuc/tglite/blob/main/docs/source/tutorial/quickstart.ipynb)\n",
    "\n",
    "This section runs through the API for common practice to perform temporal graph learning. In this tutorial, we train [TGAT](https://arxiv.org/abs/2002.07962) on [Wikipedia](https://snap.stanford.edu/jodie/) dataset as an example.\n",
    "\n",
    "## Basic settings\n",
    "\n",
    "TGLite uses [PyTorch](https://pytorch.org/) as the backend to perform tensor operations. Here we wrap some helper functions such as dataset handling in [support.py](https://github.com/ADAPT-uiuc/tglite/blob/main/examples/support.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F4O-2MjGfOMr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tglite as tg\n",
    "\n",
    "import support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set the runtime parameters, including hyper-parameters for TGAT training and system-level optimization configurations. TGLite provides several semantic-preserving system optimization options for CTDG-based models like TGAT, including deduplication, memoization, and time-precomputation. Here we enable all the optimizations with `OPT_DEDUP`, `OPT_CACHE` and `OPT_TIME` being `True`, and set the related cache size. By setting `MOVE = True`, we will make all feature data reside on GPU device memory to reduce data movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tH_6K5u3iQhy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA: str = 'wiki'  # 'wiki', 'reddit', 'mooc', 'mag', 'lastfm', 'gdelt', 'wiki-talk'\n",
    "DATA_PATH: str = '/shared'\n",
    "EPOCHS: int = 3\n",
    "BATCH_SIZE: int = 200\n",
    "LEARN_RATE: float = 0.0001\n",
    "DROPOUT: float = 0.1\n",
    "N_LAYERS: int = 2\n",
    "N_HEADS: int = 2\n",
    "N_NBRS: int = 20\n",
    "DIM_TIME: int = 100\n",
    "DIM_EMBED: int = 100\n",
    "N_THREADS: int = 32\n",
    "SAMPLING: str = 'recent'  # 'recent'or 'uniform'\n",
    "OPT_DEDUP = True\n",
    "OPT_CACHE = True\n",
    "OPT_TIME = True\n",
    "OPT_ALL = True\n",
    "OPT_DEDUP: bool = OPT_DEDUP or OPT_ALL\n",
    "OPT_CACHE: bool = OPT_CACHE or OPT_ALL\n",
    "OPT_TIME: bool = OPT_TIME or OPT_ALL\n",
    "CACHE_LIMIT: int = int(2e6)\n",
    "TIME_WINDOW: int = int(1e4)\n",
    "\n",
    "MOVE = True\n",
    "GPU = 0\n",
    "SEED = 1\n",
    "PREFIX = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, specify the training device and the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = support.make_device(GPU)\n",
    "model_path = support.make_model_path('tgat', PREFIX, DATA)\n",
    "if SEED >= 0:\n",
    "    support.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "## Loading temporal graph data\n",
    "\n",
    "[TGraph](../api/python/tglite.graph.rst) object serves as the container for node and edge tensor data. We load graph data to create a `TGraph` object `g` first, and load the features next. `TGraph` also provides the functions to manage graph data. Here, we set computation device to GPU 0 using `g.set_compute(device)`. With `g.move_data(device)`, we move graph features to GPU 0 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "COgTQXmcgCEr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num edges: 157474\n",
      "num nodes: 9228\n",
      "edge feat: torch.Size([157474, 172])\n",
      "node feat: torch.Size([9228, 172])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "g = support.load_graph(os.path.join(DATA_PATH, f'data/{DATA}/edges.csv'))\n",
    "support.load_feats(g, DATA, DATA_PATH)\n",
    "dim_efeat = 0 if g.efeat is None else g.efeat.shape[1]\n",
    "dim_nfeat = g.nfeat.shape[1]\n",
    "\n",
    "g.set_compute(device)\n",
    "if MOVE:\n",
    "    g.move_data(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "## Runtime setup\n",
    "\n",
    "TGLite uses [TContext](../api/python/tglite.context.rst) as the settings and scratch space for runtime. Here, a `TContext ctx` is initialized with the `TGraph` object `g`. Then, `ctx.need_sampling(True)` will create a TCSR structure inside `TGraph g` for more efficient sampling. Next, we invoke several functions of `ctx` to perform optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = tg.TContext(g)\n",
    "ctx.need_sampling(True)\n",
    "ctx.enable_embed_caching(OPT_CACHE, DIM_EMBED)\n",
    "ctx.enable_time_precompute(OPT_TIME)\n",
    "ctx.set_cache_limit(CACHE_LIMIT)\n",
    "ctx.set_time_window(TIME_WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "## Creating temporal sampler\n",
    "\n",
    "TGLite provides a [TSampler](../api/python/tglite.sampler.rst) module that exposes 1-hop temporal sampling. Here, by setting `num_threads`, we can control how many threads are used to perform parallel sampling. The sampler will evenly distribute the target nodes in the mini-batch to\n",
    "each thread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = tg.TSampler(N_NBRS, strategy=SAMPLING, num_threads=N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "## Creating models\n",
    "\n",
    "A [TBatch](../api/python/tglite.batch.rst) object represents a batch of temporal edges to process, which is passed to `TGAT.forward()` as the input.\n",
    "With a batch, a head `TBlock` is created. [TBlock](../api/python/tglite.block.rst) is the centerpiece of TGLite. A block essentially captures the 1-hop message-flow dependencies between target node-time pairs (i.e. destination nodes) and their temporally sampled neighbors (i.e. source nodes), along with their respective edges.\n",
    "What's more, TGLite use a doubly-linked list structure for the blocks, each representing one layer of GNN.\n",
    "Here, we iteratively perform sampling and generate TBlocks.\n",
    "\n",
    "Another feature TGLite provides to allow users to apply optimizations to `TBlock` before sampling its neighbors so to minimize the size of the following subgraphs and thus minimize potential computations.\n",
    "Here inside the loops, we invoke `dedup()` and `cache()` provided by `tglite.op` module to perform such optimizations, and then sample with passed `TSampler`.\n",
    "\n",
    "Once the full linked list of the TBlocks are created, we can load features and perform aggregation to compute node embeddings easily with functions provided by `tglite.op`.\n",
    "Here we directly use `tglite.nn.TemporalAttnLayer` to construct the TGAT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5-YKifBwLuMS"
   },
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "from tglite.nn import TemporalAttnLayer\n",
    "\n",
    "class TGAT(nn.Module):\n",
    "    def __init__(self, ctx: tg.TContext,\n",
    "                dim_node: int, dim_edge: int, dim_time: int, dim_embed: int,\n",
    "                sampler: tg.TSampler, num_layers=2, num_heads=2, dropout=0.1,\n",
    "                dedup: bool = True):\n",
    "        super().__init__()\n",
    "        self.ctx = ctx\n",
    "        self.num_layers = num_layers\n",
    "        self.attn = nn.ModuleList([\n",
    "            TemporalAttnLayer(ctx,\n",
    "                num_heads=num_heads,\n",
    "                dim_node=dim_node if i == 0 else dim_embed,\n",
    "                dim_edge=dim_edge,\n",
    "                dim_time=dim_time,\n",
    "                dim_out=dim_embed,\n",
    "                dropout=dropout)\n",
    "            for i in range(num_layers)])\n",
    "        self.sampler = sampler\n",
    "        self.edge_predictor = support.EdgePredictor(dim=dim_embed)\n",
    "        self.dedup = dedup\n",
    "\n",
    "    def forward(self, batch: tg.TBatch) -> Tensor:\n",
    "        head = batch.block(self.ctx)\n",
    "        for i in range(self.num_layers):\n",
    "            tail = head if i == 0 \\\n",
    "                else tail.next_block(include_dst=True)\n",
    "            tail = tg.op.dedup(tail) if self.dedup else tail\n",
    "            tail = tg.op.cache(self.ctx, tail.layer, tail)\n",
    "            tail = self.sampler.sample(tail)\n",
    "\n",
    "        tg.op.preload(head, use_pin=True)\n",
    "        if tail.num_dst() > 0:\n",
    "            tail.dstdata['h'] = tail.dstfeat()\n",
    "            tail.srcdata['h'] = tail.srcfeat()\n",
    "        embeds = tg.op.aggregate(head, list(reversed(self.attn)), key='h')\n",
    "        del head\n",
    "        del tail\n",
    "\n",
    "        src, dst, neg = batch.split_data(embeds)\n",
    "        scores = self.edge_predictor(src, dst)\n",
    "        if batch.neg_nodes is not None:\n",
    "            scores = (scores, self.edge_predictor(src, neg))\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the TGAT model, we can proceed to instantiate a new TGAT model with pre-set parameters and transfer it to GPU 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TGAT(ctx,\n",
    "    dim_node=dim_nfeat,\n",
    "    dim_edge=dim_efeat,\n",
    "    dim_time=DIM_TIME,\n",
    "    dim_embed=DIM_EMBED,\n",
    "    sampler=sampler,\n",
    "    num_layers=N_LAYERS,\n",
    "    num_heads=N_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    dedup=OPT_DEDUP,)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "\n",
    "## Training models\n",
    "\n",
    "Here we use [BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) as the loss function and [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is splitted into training set(70%), validating set(15%) and testing set(15%). \n",
    "`neg_sampler` randomly picks target nodes as negative samples.\n",
    "Then, we launch a `support.LinkPredTrainer` to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DLZ8cipJLx-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loss:293.4295 val ap:0.9739 val auc:0.9782\n",
      "  epoch | total:13.45s loop:11.98s eval:1.47s\n",
      "   loop | forward:6.84s backward:5.08s sample:0.68s prep_batch:0.06s prep_input:0.46s post_update:0.00s\n",
      "   comp | mem_update:0.00s time_zero:0.99s time_nbrs:0.65s self_attn:3.34s\n",
      "epoch 1:\n",
      "  loss:170.0556 val ap:0.9819 val auc:0.9843\n",
      "  epoch | total:17.91s loop:16.31s eval:1.58s\n",
      "   loop | forward:7.48s backward:8.73s sample:0.86s prep_batch:0.09s prep_input:0.55s post_update:0.00s\n",
      "   comp | mem_update:0.00s time_zero:0.36s time_nbrs:1.19s self_attn:3.63s\n",
      "epoch 2:\n",
      "  loss:142.4712 val ap:0.9833 val auc:0.9861\n",
      "  epoch | total:19.56s loop:17.82s eval:1.72s\n",
      "   loop | forward:8.03s backward:9.68s sample:0.88s prep_batch:0.09s prep_input:0.58s post_update:0.00s\n",
      "   comp | mem_update:0.00s time_zero:0.46s time_nbrs:1.43s self_attn:3.76s\n",
      "best model at epoch 2\n",
      "loading saved checkpoint and testing model...\n",
      "  test time:1.64s AP:0.9798 AUC:0.9827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_end, val_end = support.data_split(g.num_edges(), 0.7, 0.15)\n",
    "neg_sampler = lambda size: np.random.randint(0, g.num_nodes(), size)\n",
    "trainer = support.LinkPredTrainer(\n",
    "    ctx, model, criterion, optimizer, neg_sampler,\n",
    "    EPOCHS, BATCH_SIZE, train_end, val_end,\n",
    "    model_path, None)\n",
    "\n",
    "trainer.train()\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see and run more TGNN models with `tglite`, see [Running Examples](../install/index.rst#running-examples)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
